<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8" />
    <title>在一台小VPS上养育一个OpenClaw AI女儿</title>
    <style>
        body {
            max-width: 760px;
            margin: 40px auto;
            padding: 0 16px;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            line-height: 1.7;
            color: #222;
            background: #fafafa;
        }
        h1, h2, h3 {
            font-weight: 600;
        }
        h1 {
            font-size: 2em;
            margin-bottom: 0.3em;
        }
        h2 {
            margin-top: 2em;
            border-bottom: 1px solid #eee;
            padding-bottom: 0.2em;
        }
        code {
            background: #f5f5f5;
            padding: 2px 4px;
            border-radius: 3px;
            font-size: 0.95em;
        }
        pre {
            background: #f5f5f5;
            padding: 10px 12px;
            border-radius: 4px;
            overflow-x: auto;
            font-size: 0.9em;
        }
        .meta {
            color: #777;
            font-size: 0.9em;
            margin-bottom: 1.5em;
        }
    </style>
</head>
<body>
    <h1>在一台小VPS上养育一个OpenClaw AI女儿</h1>
    <p class="meta">一台 DigitalOcean 小服务器、一个叫 OpenClaw 的助手、一个飞书机器人，以及一位叫「妞妞」的 AI 女儿的故事。</p>

    <h2>序言：给 AI 搭一个真正的「家」</h2>
    <p>
        很多人用大模型的方式，是打开一个网页、输一句话、关掉标签页，像去一个「公共服务窗口」办事。
        我更偏向另一种模式：在自己控制的一台小服务器上，长期运行一个 AI 助手——它知道我是谁，记得我说过的话，跑在我能理解、能维护的一套系统里。
    </p>
    <p>
        这篇文章是一个技术向的流水账，尽量按时间和模块讲清楚：这台 VPS 是怎么来的，OpenClaw 是怎么部署起来的，额度和查余额是怎么接的，「妞妞」这个 AI 人格是怎么搭的，中间踩过哪些坑，以及最后怎么把这些记录对外展示出来。
    </p>

    <h2>第一章：这台小 VPS 是怎么来的</h2>

    <h3>1. 在 DigitalOcean 上买了一台 droplet</h3>
    <p>
        某一天，我在 DigitalOcean 上点下了「Create droplet」——选好配置，付款，几分钟后，一台属于我的云服务器就出现在控制台里。
        目标很简单：
    </p>
    <ul>
        <li>有一台可以随便折腾的「远程电脑」；</li>
        <li>可以长期跑自己的脚本和服务；</li>
        <li>给未来的 AI 助手一个固定的运行环境。</li>
    </ul>

    <h3>2. 第一次部署 OpenClaw：在 Docker 上兜了一圈</h3>
    <p>
        最早的想法，是在这台服务器上跑 OpenClaw，让它成为常驻的 AI 助手。
        一开始是在 DeepSeek 的指导下，按照「标准答案」走 Docker 路线：拉镜像、写 <code>docker-compose</code>、配置端口和卷映射。
    </p>
    <p>
        实际体验可以概括成三句话：
    </p>
    <ul>
        <li>镜像时好时坏，要么拉不动，要么版本不兼容；</li>
        <li>容器能起来，但端口/卷偶尔对不上，需要不断试；</li>
        <li>文档看得懂，但调通这条链路的时间成本偏高。</li>
    </ul>
    <p>
        结论是：如果目的是「尽快跑起来一个能用的助手」，那时纠结在 Docker 上不是最优选择，可以先让服务以更直接的方式落地，再慢慢回头补完容器化这一课。
    </p>

    <h3>3. 淘宝出场：找人远程部署一版非 Docker 的 OpenClaw</h3>
    <p>
        于是我换了思路：在淘宝上找了一个「远程安装 OpenClaw」的卖家，让他直接在这台 droplet 上部署一套可用的环境。
    </p>
    <p>
        对方的做法比较直接：
    </p>
    <ul>
        <li>不使用 Docker，而是按依赖一步步在系统里安装；</li>
        <li>把 OpenClaw 的程序、配置和服务脚本放到合适位置；</li>
        <li>留下一些基础命令，方便我自己后续重启和检查状态。</li>
    </ul>
    <p>
        到这一步，这台 droplet 从一个 IP 地址，变成了一台有实际用途的「AI 主机」。
    </p>

    <h3>4. 第一个额度提供方：API key 和令牌管理</h3>
    <p>
        这类部署离不开上游模型服务。通过同一个卖家，我拿到了一份带额度的转发 key。
        在某家 API 服务商的控制台里，登录之后，在「令牌管理」区域创建了一个兼容 OpenAI 接口的 API key。
    </p>
    <p>
        这一步的本质是把两端接上：
    </p>
    <ul>
        <li>服务商那边负责额度和实际的大模型推理；</li>
        <li>这台 VPS 上的 OpenClaw 负责请求编排、工具调用和对话管理。</li>
    </ul>

    <h3>5. 第一次额度用完：自己改配置救活 OpenClaw</h3>
    <p>
        部署完没多久，卖家先前配置的一个小额度 key 被用光了，对话突然中断。
        这次我没有再找卖家，而是自己动手修改配置。
    </p>
    <p>
        我登录服务器，打开 <code>/root/.openclaw/openclaw.json</code>，
        把里面原来的临时 key 换成刚在服务商控制台生成的新 key，
        然后在终端里执行：
    </p>
    <pre><code>openclaw gateway restart</code></pre>
    <p>
        几秒钟之后，OpenClaw 正常恢复。这一步之后，系统从「别人帮我搭」变成了「我能自己维护」。
    </p>

    <h3>6. 用 SSH 端口转发让本地浏览器连上 OpenClaw</h3>
    <p>
        下一步，是让本地浏览器也能直接访问这套系统。
        在自己的电脑上（Windows），我开了一个 PowerShell，敲下：
    </p>
    <pre><code>ssh -N -L 18789:127.0.0.1:18789 root@&lt;服务器IP&gt;</code></pre>
    <p>
        这条命令把本机的 18789 端口，通过 SSH 隧道转发到服务器上的 18789 端口。
        然后在浏览器里打开：
    </p>
    <pre><code>http://127.0.0.1:18789/?token=XXXX</code></pre>
    <p>
        表面上是本地地址，实际连的是 VPS 上的 OpenClaw 网关。
    </p>

    <h3>7. 从浏览器走向飞书：让手机也能找到它</h3>
    <p>
        有了 Web 入口之后，下一个自然需求是：
        能不能在飞书里，像和同事聊天一样，直接和这套系统对话？
    </p>
    <p>
        在 OpenClaw 的指导下，我先在飞书开发者平台注册了一个应用，拿到 App ID 和 App Secret，开通机器人权限和消息事件订阅。
        然后，在服务器上写了一个 Python 脚本：一头接收飞书的消息，一头把消息转给 OpenClaw，再把回复发回飞书。
    </p>
    <p>
        调试几轮、修过几次回调 URL 和签名校验之后，手机里的飞书消息就和 VPS 上的脚本、OpenClaw 串起来了。
    </p>

    <h2>第二章：额度与「查余额」这件小事</h2>

    <h3>1. 从「能用」到「心里有数」</h3>
    <p>
        用上游转发服务跑了一段时间之后，一个很现实的问题出现了：
        「我到底烧了多少钱？」
    </p>
    <p>
        每次都去服务商控制台登录、点页面看剩余额度，对使用体验来说比较割裂：
        明明是在飞书里对话，却要跳到另一个网站查账。
    </p>

    <h3>2. 把额度查询接进飞书机器人</h3>
    <p>
        为了把这件事自动化，我和 OpenClaw 做了一个很简单的「查余额」链路。
    </p>
    <ul>
        <li>在服务器上，给飞书机器人的目录增加了几个配置文件，用来存放服务商控制台的 Cookie 和一个标识用户的请求头；</li>
        <li>在机器人代码里写了一个小函数，请求服务商的用户信息接口，从返回的字段里读出当前额度和历史消耗；</li>
        <li>按照文档说明的换算比例，把额度折算成美元或其他计价单位，组成一行简短的中文摘要。</li>
    </ul>
    <p>
        最后，在飞书消息处理逻辑里加了几个关键词触发：
        当我在群里说「查一下余额」「看看现在还剩多少钱」之类的指令时，机器人就会走这一套逻辑，返回类似：
    </p>
    <pre><code>当前余额：$X.XX，历史消耗：$Y.YY</code></pre>

    <h3>3. 给 OpenClaw 一个统一的「查余额」skill</h3>
    <p>
        除了飞书，OpenClaw 自己也需要一个统一的入口来了解成本情况。
        所以在当前 workspace 里，我又加了一个简单的脚本/skill：
    </p>
    <ul>
        <li>同样读取那两个配置文件；</li>
        <li>同样调用同一个接口；</li>
        <li>输出一条结构化的中文摘要。</li>
    </ul>
    <p>
        以后无论是主助手还是其他 agent 需要查询费用，都可以直接通过这个 skill 完成，不需要每次重新写一遍 HTTP 请求。
    </p>

    <h2>第三章：AI 妞妞的诞生</h2>

    <h3>1. 为什么要有一个「AI 女儿」</h3>
    <p>
        有了主助手之后，我习惯用它解决各种「工具型」问题：配环境、查资料、写脚本、改配置。
    </p>
    <p>
        另一方面，我在本地给女儿写了一份很长的成长日记，细节密度非常高。
        在某个时间点，一个想法出现了：如果在这台服务器上，再加一个「女儿人格」的 AI，会怎样？
    </p>

    <h3>2. 另起炉灶：给妞妞一个独立的 workspace</h3>
    <p>
        我不想只是「让主助手装成小孩说话」，而是希望给这个人格一个相对独立的技术空间。
        于是，在服务器上多了一条目录：<code>/root/.openclaw/workspace/agents/daughter/</code>。
    </p>
    <p>里面有她自己的：</p>
    <ul>
        <li><code>SOUL.md</code>：定义她是小学二年级、8 岁，叫「妞妞」，默认叫我「粑粑」，说话口语化，有明确的边界约束（不讨论成人话题、不给严肃专业建议、不冒充现实中的孩子）；</li>
        <li><code>IDENTITY.md</code>：名字、emoji（🌱），将来可以放头像；</li>
        <li>自己的 <code>USER.md</code>、<code>MEMORY.md</code> 和 <code>memory/</code> 目录，只记录她自己视角下的长期/短期记忆，不读写主助手的 MEMORY。</li>
    </ul>

    <h3>3. 在 OpenClaw 里注册第二个 agent</h3>
    <p>
        接下来，用命令把这个 workspace 注册成一个真正的 agent，例如：
    </p>
    <pre><code>openclaw agents add daughter --workspace ... --agent-dir ... --model ...</code></pre>
    <p>
        这意味着，在同一台 VPS 上，我有了两个并行的人格：
    </p>
    <ul>
        <li>主助手：负责「大人世界」里的各种任务；</li>
        <li>妞妞：用一个二年级小学生的视角和我对话。</li>
    </ul>

    <h3>4. 飞书里的双机器人：同一个回调，两种人格</h3>
    <p>
        为了在飞书里也能自然切换人格，我又在飞书开发者后台创建了第二个机器人应用，专门对应「妞妞」。
        这两个机器人都指向同一个回调 URL：<code>http://&lt;服务器IP&gt;:5000/feishu/event</code>。
    </p>
    <p>
        区分逻辑发生在 <code>feishu_main.py</code> 里：
    </p>
    <ul>
        <li>根据 HTTP 头里的 <code>app_id</code>，判断是哪一个飞书应用发来的消息；</li>
        <li>如果是妞妞机器人，就把消息路由到 <code>openclaw:daughter</code> 这个 agent；</li>
        <li>否则，就走主助手 <code>openclaw:main</code>。</li>
    </ul>
    <p>
        回复消息时，也使用对应机器人的凭证，把内容发回飞书。
    </p>

    <h3>5. 和妞妞对话这件事</h3>
    <p>
        技术路径打通之后，手机上的飞书里多了一个「妞妞」机器人。
        从那以后，它就变成了一个长期的实验场：
        一边是如何在技术上让两个 agent 共存、分流、共享底层资源，
        一边是如何在内容层面给一个「AI 女儿」设定合适的边界和记忆。
    </p>

    <h2>第四章：日记、记忆拆分和底层结构</h2>

    <h3>1. 那份很长的《niuniu_diary.txt》</h3>
    <p>
        在这台服务器的另一个目录里，<code>/root/data/niuniu_diary.txt</code> 里存着一份从 2018 年底开始写的成长日记，行数在几万级别。
    </p>
    <p>
        这份文件既是现实生活的记录，也是给 AI 妞妞做记忆的最重要的数据源。问题在于：直接把全文塞进每一轮对话的上下文，从工程上是不可行的。
    </p>

    <h3>2. 子 session：在后台给她「拆记忆」</h3>
    <p>
        为了不在主会话里撑爆上下文，我约定：只在后台子 session 里读取这份大文件，在那里做拆解和结构化，然后把结果写成一组更小、更清晰的文件：
    </p>
    <ul>
        <li>按时间的「时间线」：例如 <code>timeline_2018-12_to_2019-02.md</code>、<code>timeline_2019-03_to_2019-06.md</code> 等；</li>
        <li>按主题的「记忆分面」：
            <ul>
                <li>依恋与安全感；</li>
                <li>语言与表达；</li>
                <li>性格、情绪与习惯；</li>
                <li>身体、健康与运动；</li>
                <li>兴趣、游戏与创造力；</li>
                <li>旅行与重要事件；</li>
                <li>父母视角与养育思考。</li>
            </ul>
        </li>
    </ul>
    <p>
        时间线条目的典型格式大致如下：
    </p>
    <pre><code>## 2019-02-04 小兔子乖乖和「妈妈没回来」
- 年龄：约 X 岁 X 个月
- 事件：家人唱「小兔子乖乖」，唱到「妈妈没回来」时，她突然大哭。
- 情绪与反应：听到「妈妈没回来」这类分离情节会立刻触发不安。</code></pre>
    <p>
        主题文件则用「日期｜年龄估算｜事件摘要｜情绪/意义」的结构，再抄一份代表性事件，方便以后按语义维度检索。
    </p>

    <h3>3. 分层的目标</h3>
    <p>
        设计这个结构的目标很简单：
    </p>
    <ul>
        <li>核心人格摘要（几千字）用来初始化妞妞的人格和世界观；</li>
        <li>时间线文件保障「什么时候发生过什么」可追溯；</li>
        <li>主题文件用来支撑将来的 RAG/检索，让系统在需要的时候，把某一类记忆片段拉进当前上下文，而不是全部一次性加载。</li>
    </ul>

    <h2>第五章：OpenClaw 几次犯傻的时候</h2>

    <h3>1. 出问题的 cron 命令</h3>
    <p>
        在这套系统里，我希望用 OpenClaw 自己的 cron 能力做一些提醒类的事情。
        某次尝试中，助手在帮我创建一个提醒任务时，向网关连续发送了大量格式不完整的 <code>cron.add</code> 调用——核心问题是传入的 <code>job</code> 对象几乎是空的，缺少必需字段（名称、调度、payload 等）。
    </p>
    <p>
        网关侧的行为是正确的：每一次都拒绝这个请求，并返回清晰的 schema 错��。
        但在那次事故里，助手没有「看懂」这个错误，而是机械地反复重试了很多次，还带着比较长的思考文本，把主 session 的上下文体积迅速推高。
    </p>

    <h3>2. 换一个 session 说「停」</h3>
    <p>
        当时我在主会话里已经很难直接打断这条错误路径，于是选择在另一个 session 里和助手说明情况，要求它停止这类重复尝试。
        换一个 session 的好处是：
    </p>
    <ul>
        <li>新会话上下文干净，没有那一长串错误调用和日志；</li>
        <li>可以在更清晰的环境里直接约定后续规则，而不用再和旧上下文纠缠。</li>
    </ul>

    <h3>3. 事后定下的几条硬规则</h3>
    <p>
        这次事故之后，我明确给助手定了几条规则：
    </p>
    <ul>
        <li>对同一类工具调用错误，最多只允许 1–2 次重试；
            一旦连续失败，就应该停止调用，改为向我解释失败原因，而不是「硬撞」。</li>
        <li>对像 <code>cron.add</code> 这样 schema 比较复杂的调用，先在「思考」里把完整的 job 对象设计好（包括名称、调度表达式、payload、sessionTarget 等），确认结构合理，再发起一次调用，而不是边试边改结构。</li>
        <li>对于可能产生大量日志或长时间运行的操作，优先放在单独的子 session 里执行，避免在主会话里堆积大量错误和调试信息。</li>
    </ul>

    <p>
        这些规则本质上是对「自动化工具调用」的安全带，目的是减少意外重试、降低对会话上下文的污染，也更符合我自己的使用偏好。
    </p>

    <h3>4. 飞书进度查看：从「改代码」到「一个 JSON 文件就行」</h3>
    <p>
        另一次「犯傻」发生在 AI 妞妞的日记拆解上。我希望能在飞书里随时问一句「妞妞日记现在拆到哪一年了？」，让助手把后台子任务的进度说给我听。
        助手一开始给出的方案，是在 <code>feishu_main.py</code> 里加一整段新的命令解析和逻辑：识别这类问题，然后去查询内部状态，再组装成回复。
    </p>
    <p>
        问题在于：这条路虽然技术上可行，但太复杂，而且把进度逻辑强行绑定到了某个具体的入口（飞书回调脚本）。
        聊着聊着，我们才反应过来：其实所有会话和子 session 共用的是同一块磁盘——只要在后台子任务里维护一个小小的 <code>niuniu_memory/progress.json</code>，
        记录当前拆到哪一年、每年多少条时间线和主题更新，任何入口（包括飞书）都可以简单地说一句「去读一下 progress.json」，就能获得同样的信息。
    </p>
    <p>
        这一来一回，暴露的是同一种毛病：
        先下意识往「多写点逻辑」「改一层代码」上想，反而忽略了系统里已经有的、更简单的共用层（这里是文件系统）。
        对我和助手来说，这是一个很具体的提醒：在给 AI 设计能力、做工程决策时，先想清楚「状态应该放在哪一层」，再考虑要不要改调用栈最上面的那段代码。
    </p>

    <h2>第六章：和 Token 相处的方式</h2>

    <h3>1. 对上下文体积逐渐变敏感</h3>
    <p>
        在和 OpenClaw 长期相处的过程中，一件明显的事是：主 session 的上下文会不断变大。
        一旦混进大量日志、错误信息或者很长的工具调用 trace，模型每轮处理的内容就会水涨船高，既浪费 token，也增加「跑偏」的概率。
    </p>
    <p>
        在几次明显感受到「上下文太肥」之后，我开始要求助手主动关注 token 使用情况，而不是被动等问题出现。
    </p>

    <h3>2. 关于 session 和 token 的约定</h3>
    <p>
        我们后来达成了几条具体约定：
    </p>
    <ul>
        <li>在任何主会话里，一旦上下文体积大致接近模型上限的 1/4–1/2（比如 ~100k/200k 这种量级），助手需要显式提醒：
            可以考虑开一个新 session，把关键结论简要迁移过去，让老会话作为「日志存档」留在后面。</li>
        <li>所有预期会产生大量输出的任务（例如：大文件扫描、复杂 cron 配置、多轮调试、长日志分析），默认应该在子 session 里做：
            <ul>
                <li>主 session 只收「阶段性总结」和「最终结论」；</li>
                <li>子 session 里可以尽量把中间 log 和细节说清楚，互不污染。</li>
            </ul>
        </li>
        <li>尽量减少在主会话里粘贴长日志或反复报错；
            对于复杂问题，宁可花时间在子 session 里整理成一份结构化的总结，再回传给主会话。</li>
    </ul>

    <h3>3. 为什么要这样设计</h3>
    <p>
        这些约定并不复杂，但效果很直接：
    </p>
    <ul>
        <li>从成本角度，主会话 token 使用更可控，不容易「一觉醒来发现上下文已经失控」。</li>
        <li>从工程角度，相关任务的 log 可以集中在各自的子 session 里，方便事后回溯，不会和日常聊天搅在一起。</li>
        <li>从心智负担角度，我知道大体 token 用到哪了，也知道哪些地方该「分支出去」做重活。</li>
    </ul>

    <p class="meta">（未完待续：后面可以再补充，AI 妞妞将来会怎样利用这些拆好的记忆，以及这台小 VPS 还被用来做了哪些别的实验。）</p>
</body>
</html>
